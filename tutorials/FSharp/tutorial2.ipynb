{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: TorchSharp-cpu\"\n",
    "\n",
    "open TorchSharp\n",
    "open type TorchSharp.TensorExtensionMethods\n",
    "\n",
    "open Microsoft.DotNet.Interactive.Formatting\n",
    "Formatter.SetPreferredMimeTypesFor(typeof<torch.Tensor>, \"text/plain\")\n",
    "Formatter.Register<torch.Tensor>(fun (x:torch.Tensor) -> x.ToString(true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "source": [
    "# Tensors\n",
    "\n",
    "In TorchSharp, as in all deep learning, the fundamental data type is a 'tensor,' which is simply a generalized matrix. In Linear Algebra, a one-dimensional arrays are called 'vector,' and a two-dimensional array is a 'matrix.' Generalizing on that, a tensor is simply an N-dimensional array. \n",
    "\n",
    "Please note that there is an overloaded use of the word 'dimensions' here -- in physics, a vector (one dimension) with three elements is used to represents a point in space, one element for each spatial dimension. When we speak of 'dimension' in these tutorials, it is the number of tensor dimensions that is of interest.\n",
    "\n",
    "So, let's get started with tensors by creating some."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant-Filled Tensors\n",
    "\n",
    "The simplest tensor creation primitives just initializes a tensor with either 0 or 1 in all its elements. The arguments passed in is the size of each dimension. Think of the first dimension as the rows of a table, the second as the columns, and then you just have to generalize things in your head after that. In the examples below, we'll mostly be creating 3x4 matrices, for simplicity.\n",
    "\n",
    "One thing to note is that .NET Interactive will show the object and its fields, etc. when you say just 't' at the end of the notebook cell. What we want for tensors is to show the contents, and there's a special version of ToString() taking a Boolean that shows not just the size and type of the tensor, but also its contents. The special .NET Interactive formatter that is found at the top of the notebook (and should be at the top of all notebooks using TorchSharp) uses TorString(true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "let t = torch.ones(3, 4)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have more than two dimensions, the special version of ToString(t) will try to format it in a way that makes sense to a human:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.ones(2,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you intend to fill the tensor with values from somewhere else, in other words because you pre-allocated it, there's an 'empty' factory that is faster than using anything else. The values are just whatever was found in memory when the tensor was created. Don't mistake that for random values, though -- they won't adhere to any particular distribution. In fact, one of the main uses for empty tensors is to create one, and then fill it with random numbers from some particular distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.empty(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a tensor from any value you want. F# doesn't yet support implicit conversions, to for the time being, we have to explicitly convert some operands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.full(4,4,3.14f.ToScalar())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you want to display more than one value in a cell. To do that, you need to rely on good-old-fashioned printing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "Console.Write(torch.zeros(4,4).ToString(true));\n",
    "Console.Write(torch.ones(4,4).ToString(true));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that typing will get pretty tedious, so we added an extension method `print()` that is much quicker to type. It really should only be used in notebooks.\n",
    "\n",
    "`print()` returns the tensor it's invoked on. In C#, adding a ';' to the end of the last line supresses the automatic printing of the last value, but the same isn't true for F#. In order to avoid printing the last expression, you have to send it to `ignore()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "// This doesn't work yet -- wait for the next release:\n",
    "torch.zeros(4,4).print()\n",
    "torch.ones(4,4).print() |> ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that each tensor has a 'type = Float32' attribute. This is a peculiarity about the TorchSharp tensor type -- the element type does not show up in the type, Tensor is not Tensor\\<T\\>. This is so because the underlying C++ / CUDA runtime represents tensors this way, and it makes it easier to port code from Python, too.\n",
    "\n",
    "You may also have noticed that tensors are created using factories, not constructors. Also, the naming convention doesn't look anything like .NET. We chose to step away from .NET conventions in order to make it easier to port code from Python. We know this will upset some, and please some, but it's the decision we came to after a long time of deliberating.\n",
    "\n",
    "Anyway, 'Float32' is the default, but you can create tensors of other types, too, including complex tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.zeros(4,4, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.zeros(4, 4, dtype=torch.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the contents of a tensor, you treat it as a multi-dimensional array (note that the number of dimensions also isn't part of the type itself). When you do, you'll be surprised to see that the result of the indexing operator is another tensor, one that has no shape -- this is how TorchSharp represents a scalar value. Later in this tutorial, we will see why. For now, just know that you have to extract the value using a function, based on the type you expect to get out.\n",
    "\n",
    "In PyTorch, there's a method '.item()' used for this purpose. In TorchSharp, it's a templatized method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "let t = torch.zeros(4,4, dtype=torch.int32)\n",
    "t.[0L,0L].print()\n",
    "t.[0L,0L].item<int>()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write to a single element, you have to create a tensor from the value you want to write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "t.[0L,0L] <- torch.tensor(35)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Tensors\n",
    "\n",
    "In machine learning, random number generation is very important, and you often end up using the RNG APIs to create tensors. There are a big number of RNGs, most of them for floating point values, but there are some for integers, too.\n",
    "\n",
    "The usual suspects are present -- normal and uniform distributions, binomial (true/false or 0/1) and uniformly distributed integers. A separate tutorial will disscuss random number generation in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "// Normal distribution\n",
    "torch.randn(3L,4L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "// Uniform distribution between [0,1[\n",
    "torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "// Uniform distribution between [100,110[\n",
    "(torch.rand(3,4) * torch.tensor(10) + torch.tensor(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranges\n",
    "\n",
    "Another common and convenient tensor factory is `arange()`, which is used to create a 1D tensor with numbers ranging from a min to a max, exclusive of the max. You can provide the step value, or let it be the default, which is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.arange(3L.ToScalar(),14L.ToScalar())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `arange` behaves a little differently from other factories -- the default element type is not float32, it's inferred from the arguments. To use floating-point, we an either specify the type, or use floating-point values as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.arange(3.0f.ToScalar(), 14.0f.ToScalar())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step argument will allow us to get a more fine-grained number series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.arange(3.0f.ToScalar(), 5.0f.ToScalar(), step=0.1f.ToScalar())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no way to make `arange` produce anything but a 1D tensor, so a common thing to do is to reshape it as soon as it's created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.arange(3.0f.ToScalar(), 5.0f.ToScalar(), step=0.1f.ToScalar()).reshape(4L,5L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When printing out floating-point tensors, it is often helpful to provide a formatting string, applied only to FP elements, including the real and imaginary parts of complex numbers. `.ToString(true, \"0.00\")` would be a lot to type every time, so TorcSharp defines a shorter (and Python-looking) method `str()` that does the trick. `print()` also takes a format string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.arange(3.0f.ToScalar(), 5.0f.ToScalar(), step=0.1f.ToScalar()).reshape(4L,5L).str(\"0.00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Tensor Properties and Operations\n",
    "\n",
    "There is a large number of operations on tensors. Here are some of the most commonly used ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "let t = torch.arange(3.0f.ToScalar(), 5.0f.ToScalar(), step=0.1f.ToScalar()).reshape(2L,2L,5L);\n",
    "\n",
    "// The overall shape of the tensor:\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "// The number of dimensions:\n",
    "t.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "// The total number of elements held in the tensor:\n",
    "t.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "// Move the tensor to the GPU and back to the CPU:\n",
    "\n",
    "// t.cuda() // Uncomment if you're using one of the CUDA backends.\n",
    "t.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.arange(3.0f.ToScalar(), 5.0f.ToScalar(), step=0.1f.ToScalar()).reshape(4L,5L).print()\n",
    "torch.arange(3.0f.ToScalar(), 5.0f.ToScalar(), step=0.1f.ToScalar()).reshape(4L,5L).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that transposing isn't the same as simply reshaping to a different shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.arange(3.0f.ToScalar(), 5.0f.ToScalar(), step=0.1f.ToScalar()).reshape(5L,4L).print()\n",
    "torch.arange(3.0f.ToScalar(), 5.0f.ToScalar(), step=0.1f.ToScalar()).reshape(4L,5L).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "// Clone a tensor:\n",
    "let s = t.clone()\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorcgSharp has great support for complex tensors, which are as easy to create as others. Complex numbers are commonly used in signal processing scenarios, such as audio analysis. Complex numbers have two components -- the real and the imaginary parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "let ct = torch.rand(3,4,dtype=torch.ScalarType.ComplexFloat32);\n",
    "ct.str(\"0.00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the real and imaginary parts, there are property accessors for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "ct.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "ct.imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create random complex tensors, both the real and imaginary parts are random. However, when you create a tensor with `torch.ones`, only the real part is filled in -- the imaginary part is '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.ones(3,4,dtype=torch.ScalarType.ComplexFloat32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "source": [
    "Experienced PyTorch users will notice that TorchSharp doesn't represent complex numbers in the str() output exactly the same: TorchSharp uses 'i' instead of 'j' to indicate the imaginary part, and we don't print the real or imaginary part if it is zero (unless they are both zero, of course)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (F#)",
   "language": "F#",
   "name": ".net-fsharp"
  },
  "language_info": {
   "name": "F#"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
